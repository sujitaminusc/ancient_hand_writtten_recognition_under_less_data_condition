{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 13:31:40.923318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emnist_balanced(cnt):\n",
    "    from scipy import io as spio\n",
    "    #from keras.utils import to_categorical\n",
    "    import numpy as np\n",
    "    emnist = spio.loadmat(\"data/matlab/emnist-balanced.mat\")\n",
    "    \n",
    "    classes = 47\n",
    "    cnt = cnt\n",
    "    lim_train = cnt*classes\n",
    "    \n",
    "    x_train = emnist[\"dataset\"][0][0][0][0][0][0]\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
    "    x_test = emnist[\"dataset\"][0][0][1][0][0][0]\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1, order=\"A\").astype('float32') / 255.\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1, order=\"A\").astype('float32') / 255.\n",
    " \n",
    "    y_train = (y_train.astype('float32'))\n",
    "    y_test = tf.keras.utils.to_categorical(y_test.astype('float32'))   \n",
    "    \n",
    "    #Append equal number of training samples from each class to x_train and y_train\n",
    "    x_tr = []\n",
    "    y_tr = []\n",
    "    count = [0] * classes\n",
    "    for i in range(0,x_train.shape[0]):\n",
    "        if (sum(count)==classes*cnt):\n",
    "            break\n",
    "        name = (y_train[i])\n",
    "        if (count[int(name)]>=cnt):\n",
    "            continue\n",
    "        count[int(name)] = count[int(name)]+1\n",
    "        x_tr.append(x_train[i])\n",
    "        y_tr.append(name)\n",
    "    x_tr = np.asarray(x_tr)\n",
    "    y_tr = np.asarray(y_tr)\n",
    "    y_tr = tf.keras.utils.to_categorical(y_tr.astype('float32'))\n",
    "    \n",
    "    print(x_tr.shape,y_tr.shape,x_test.shape,y_test.shape)\n",
    "    return (x_tr, y_tr), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112800, 28, 28, 1) (112800, 47) (18800, 28, 28, 1) (18800, 47)\n",
      "Epoch 1/100\n",
      "3525/3525 [==============================] - 310s 87ms/step - loss: 0.6904 - accuracy: 0.7777 - val_loss: 0.4047 - val_accuracy: 0.8593\n",
      "Epoch 2/100\n",
      "3525/3525 [==============================] - 355s 101ms/step - loss: 0.4415 - accuracy: 0.8458 - val_loss: 0.3761 - val_accuracy: 0.8624\n",
      "Epoch 3/100\n",
      "3525/3525 [==============================] - 394s 112ms/step - loss: 0.3973 - accuracy: 0.8578 - val_loss: 0.3400 - val_accuracy: 0.8775\n",
      "Epoch 4/100\n",
      "3525/3525 [==============================] - 414s 118ms/step - loss: 0.3646 - accuracy: 0.8682 - val_loss: 0.3252 - val_accuracy: 0.8827\n",
      "Epoch 5/100\n",
      "3525/3525 [==============================] - 417s 118ms/step - loss: 0.3420 - accuracy: 0.8740 - val_loss: 0.3270 - val_accuracy: 0.8820\n",
      "Epoch 6/100\n",
      "3525/3525 [==============================] - 414s 117ms/step - loss: 0.3280 - accuracy: 0.8789 - val_loss: 0.3242 - val_accuracy: 0.8836\n",
      "Epoch 7/100\n",
      "3525/3525 [==============================] - 402s 114ms/step - loss: 0.3148 - accuracy: 0.8827 - val_loss: 0.3086 - val_accuracy: 0.8854\n",
      "Epoch 8/100\n",
      "3525/3525 [==============================] - 393s 112ms/step - loss: 0.3030 - accuracy: 0.8865 - val_loss: 0.3207 - val_accuracy: 0.8873\n",
      "Epoch 9/100\n",
      "3525/3525 [==============================] - 391s 111ms/step - loss: 0.2958 - accuracy: 0.8886 - val_loss: 0.3080 - val_accuracy: 0.8884\n",
      "Epoch 10/100\n",
      "3525/3525 [==============================] - 380s 108ms/step - loss: 0.2898 - accuracy: 0.8898 - val_loss: 0.3129 - val_accuracy: 0.8901\n",
      "Epoch 11/100\n",
      "3525/3525 [==============================] - 375s 106ms/step - loss: 0.2807 - accuracy: 0.8932 - val_loss: 0.3038 - val_accuracy: 0.8954\n",
      "Epoch 12/100\n",
      "3525/3525 [==============================] - 381s 108ms/step - loss: 0.2762 - accuracy: 0.8950 - val_loss: 0.3088 - val_accuracy: 0.8922\n",
      "Epoch 13/100\n",
      "3525/3525 [==============================] - 399s 113ms/step - loss: 0.2728 - accuracy: 0.8959 - val_loss: 0.3087 - val_accuracy: 0.8905\n",
      "Epoch 14/100\n",
      "3525/3525 [==============================] - 409s 116ms/step - loss: 0.2686 - accuracy: 0.8970 - val_loss: 0.3037 - val_accuracy: 0.8925\n",
      "Epoch 15/100\n",
      "3525/3525 [==============================] - 393s 111ms/step - loss: 0.2660 - accuracy: 0.8978 - val_loss: 0.3063 - val_accuracy: 0.8960\n",
      "Epoch 16/100\n",
      "3525/3525 [==============================] - 430s 122ms/step - loss: 0.2606 - accuracy: 0.8981 - val_loss: 0.3052 - val_accuracy: 0.8937\n",
      "Epoch 17/100\n",
      "3525/3525 [==============================] - 396s 112ms/step - loss: 0.2565 - accuracy: 0.9000 - val_loss: 0.3076 - val_accuracy: 0.8939\n",
      "Epoch 18/100\n",
      "3525/3525 [==============================] - 424s 120ms/step - loss: 0.2571 - accuracy: 0.8997 - val_loss: 0.3025 - val_accuracy: 0.8969\n",
      "Epoch 19/100\n",
      "3525/3525 [==============================] - 455s 129ms/step - loss: 0.2521 - accuracy: 0.9018 - val_loss: 0.3087 - val_accuracy: 0.8926\n",
      "Epoch 20/100\n",
      "3525/3525 [==============================] - 452s 128ms/step - loss: 0.2528 - accuracy: 0.9004 - val_loss: 0.3245 - val_accuracy: 0.8907\n",
      "Epoch 21/100\n",
      "3525/3525 [==============================] - 428s 121ms/step - loss: 0.2494 - accuracy: 0.9019 - val_loss: 0.3209 - val_accuracy: 0.8915\n",
      "Epoch 22/100\n",
      "3525/3525 [==============================] - 397s 113ms/step - loss: 0.2471 - accuracy: 0.9043 - val_loss: 0.3139 - val_accuracy: 0.8924\n",
      "Epoch 23/100\n",
      "3525/3525 [==============================] - 383s 109ms/step - loss: 0.2441 - accuracy: 0.9034 - val_loss: 0.3187 - val_accuracy: 0.8935\n",
      "Epoch 24/100\n",
      "3525/3525 [==============================] - 350s 99ms/step - loss: 0.2430 - accuracy: 0.9040 - val_loss: 0.3161 - val_accuracy: 0.8941\n",
      "Epoch 25/100\n",
      " 567/3525 [===>..........................] - ETA: 5:04 - loss: 0.2240 - accuracy: 0.9100"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb Cell 3\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb#W2sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m model\u001b[39m.\u001b[39mfit(x_train, y_train, validation_data\u001b[39m=\u001b[39m(x_test, y_test), epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb#W2sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/apple/Desktop/new_project_ml/once_again/textcaps/emnist.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39memnist_model.hdf5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1808\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    869\u001b[0m       args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    870\u001b[0m   )\n\u001b[1;32m    871\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming you have the necessary imports and load_emnist_balanced function\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_emnist_balanced(20000)\n",
    "\n",
    "# Define the CNN model\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(47, activation='softmax'))  # Assuming 10 classes (adjust as needed)\n",
    "\n",
    "model = models.Sequential()  \n",
    "model.add(layers.Conv2D(28, (5, 5), padding='same', input_shape=x_train.shape[1:]))  \n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.BatchNormalization())  \n",
    "model.add(layers.Conv2D(28, (5, 5)))  \n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(32, (5, 5), padding='same'))\n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.BatchNormalization())  \n",
    "model.add(layers.Conv2D(32, (5, 5)))  \n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.MaxPool2D(pool_size=(2, 2)))  \n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())  \n",
    "model.add(layers.Dense(512))  \n",
    "model.add(layers.Activation('relu'))  \n",
    "model.add(layers.Dropout(0.25))  \n",
    "model.add(layers.Dense(47))  \n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)  # Adjust the learning rate as needed\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)\n",
    "\n",
    "# Save the model\n",
    "model.save('emnist_model.hdf5')\n",
    "\n",
    "# Load and evaluate the model\n",
    "model = tf.keras.models.load_model('emnist_model.hdf5')\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples per class: {0: 2400, 1: 2400, 2: 2400, 3: 2400, 4: 2400, 5: 2400, 6: 2400, 7: 2400, 8: 2400, 9: 2400, 10: 2400, 11: 2400, 12: 2400, 13: 2400, 14: 2400, 15: 2400, 16: 2400, 17: 2400, 18: 2400, 19: 2400, 20: 2400, 21: 2400, 22: 2400, 23: 2400, 24: 2400, 25: 2400, 26: 2400, 27: 2400, 28: 2400, 29: 2400, 30: 2400, 31: 2400, 32: 2400, 33: 2400, 34: 2400, 35: 2400, 36: 2400, 37: 2400, 38: 2400, 39: 2400, 40: 2400, 41: 2400, 42: 2400, 43: 2400, 44: 2400, 45: 2400, 46: 2400}\n",
      "Test samples per class: {0: 400, 1: 400, 2: 400, 3: 400, 4: 400, 5: 400, 6: 400, 7: 400, 8: 400, 9: 400, 10: 400, 11: 400, 12: 400, 13: 400, 14: 400, 15: 400, 16: 400, 17: 400, 18: 400, 19: 400, 20: 400, 21: 400, 22: 400, 23: 400, 24: 400, 25: 400, 26: 400, 27: 400, 28: 400, 29: 400, 30: 400, 31: 400, 32: 400, 33: 400, 34: 400, 35: 400, 36: 400, 37: 400, 38: 400, 39: 400, 40: 400, 41: 400, 42: 400, 43: 400, 44: 400, 45: 400, 46: 400}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import io as spio\n",
    "\n",
    "# Load the EMNIST dataset\n",
    "emnist = spio.loadmat(\"data/matlab/emnist-balanced.mat\")\n",
    "\n",
    "# Extract training and test labels\n",
    "y_train = emnist[\"dataset\"][0][0][0][0][0][1]\n",
    "y_test = emnist[\"dataset\"][0][0][1][0][0][1]\n",
    "\n",
    "# Count the number of samples per class\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique, counts))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "test_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Training samples per class:\", train_counts)\n",
    "print(\"Test samples per class:\", test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c3a3d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 18:43:57.312045: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.1675 - accuracy: 0.9435 - val_loss: 0.1758 - val_accuracy: 0.9436\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0606 - accuracy: 0.9795 - val_loss: 0.1619 - val_accuracy: 0.9498\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.1778 - val_accuracy: 0.9470\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.1676 - val_accuracy: 0.9512\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.1845 - val_accuracy: 0.9510\n",
      "313/313 - 1s - loss: 0.1845 - accuracy: 0.9510 - 646ms/epoch - 2ms/step\n",
      "\n",
      "Test accuracy: 0.9509999752044678\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Assuming 10 classes (adjust as needed)\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Adjust the learning rate as needed\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with early stopping and Adam optimizer\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9609999752044678\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTest accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
